<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>pika主从同步原理 | Pika 文档</title>
    <meta name="generator" content="VuePress 1.9.10">
    <link rel="icon" href="/pika-logo-trans.png">
    <meta name="description" content=" ">
    
    <link rel="preload" href="/assets/css/0.styles.f6912c97.css" as="style"><link rel="preload" href="/assets/js/app.fdecc826.js" as="script"><link rel="preload" href="/assets/js/7.1224f65b.js" as="script"><link rel="preload" href="/assets/js/2.9fbd6685.js" as="script"><link rel="preload" href="/assets/js/1.77f24ecd.js" as="script"><link rel="preload" href="/assets/js/51.b06f7ce0.js" as="script"><link rel="prefetch" href="/assets/js/10.dfb0299a.js"><link rel="prefetch" href="/assets/js/100.816240cd.js"><link rel="prefetch" href="/assets/js/101.94bf3c69.js"><link rel="prefetch" href="/assets/js/102.39c0613b.js"><link rel="prefetch" href="/assets/js/103.35b975ea.js"><link rel="prefetch" href="/assets/js/104.0b5155b5.js"><link rel="prefetch" href="/assets/js/105.897db006.js"><link rel="prefetch" href="/assets/js/11.479e3941.js"><link rel="prefetch" href="/assets/js/14.65104886.js"><link rel="prefetch" href="/assets/js/15.0fe19f29.js"><link rel="prefetch" href="/assets/js/16.3a98beb2.js"><link rel="prefetch" href="/assets/js/17.85dc844f.js"><link rel="prefetch" href="/assets/js/18.060d220d.js"><link rel="prefetch" href="/assets/js/19.77ed2e0b.js"><link rel="prefetch" href="/assets/js/20.1faabea6.js"><link rel="prefetch" href="/assets/js/21.4913a81b.js"><link rel="prefetch" href="/assets/js/22.ec2bffa8.js"><link rel="prefetch" href="/assets/js/23.77700c61.js"><link rel="prefetch" href="/assets/js/24.6badfe0e.js"><link rel="prefetch" href="/assets/js/25.bda1b3e1.js"><link rel="prefetch" href="/assets/js/26.06377f0d.js"><link rel="prefetch" href="/assets/js/27.86112ea9.js"><link rel="prefetch" href="/assets/js/28.be8ca15b.js"><link rel="prefetch" href="/assets/js/29.98f0eb72.js"><link rel="prefetch" href="/assets/js/3.50c72d76.js"><link rel="prefetch" href="/assets/js/30.4c7947d3.js"><link rel="prefetch" href="/assets/js/31.aa1f8d83.js"><link rel="prefetch" href="/assets/js/32.bac8f00d.js"><link rel="prefetch" href="/assets/js/33.cb9d2429.js"><link rel="prefetch" href="/assets/js/34.380ce34c.js"><link rel="prefetch" href="/assets/js/35.b5fcd8bd.js"><link rel="prefetch" href="/assets/js/36.34421d06.js"><link rel="prefetch" href="/assets/js/37.974c194a.js"><link rel="prefetch" href="/assets/js/38.2d40b9d6.js"><link rel="prefetch" href="/assets/js/39.5d62c31a.js"><link rel="prefetch" href="/assets/js/4.ab7c6b55.js"><link rel="prefetch" href="/assets/js/40.8eb7fa64.js"><link rel="prefetch" href="/assets/js/41.6ebe5fd9.js"><link rel="prefetch" href="/assets/js/42.0a10147c.js"><link rel="prefetch" href="/assets/js/43.1d002d1e.js"><link rel="prefetch" href="/assets/js/44.16165f42.js"><link rel="prefetch" href="/assets/js/45.82b1c661.js"><link rel="prefetch" href="/assets/js/46.2de6a735.js"><link rel="prefetch" href="/assets/js/47.74c2cd15.js"><link rel="prefetch" href="/assets/js/48.83bd3b51.js"><link rel="prefetch" href="/assets/js/49.4fa3f0df.js"><link rel="prefetch" href="/assets/js/5.8a3b91a7.js"><link rel="prefetch" href="/assets/js/50.a2bec2c8.js"><link rel="prefetch" href="/assets/js/52.a31c1acf.js"><link rel="prefetch" href="/assets/js/53.eee419ce.js"><link rel="prefetch" href="/assets/js/54.a16795f6.js"><link rel="prefetch" href="/assets/js/55.c766ad4e.js"><link rel="prefetch" href="/assets/js/56.0d79eb6c.js"><link rel="prefetch" href="/assets/js/57.7840293a.js"><link rel="prefetch" href="/assets/js/58.754a0b66.js"><link rel="prefetch" href="/assets/js/59.fbe66214.js"><link rel="prefetch" href="/assets/js/6.2727d8db.js"><link rel="prefetch" href="/assets/js/60.ee47f18b.js"><link rel="prefetch" href="/assets/js/61.b283a4ad.js"><link rel="prefetch" href="/assets/js/62.c97c0357.js"><link rel="prefetch" href="/assets/js/63.d875ed15.js"><link rel="prefetch" href="/assets/js/64.e5a2f094.js"><link rel="prefetch" href="/assets/js/65.ca32c88d.js"><link rel="prefetch" href="/assets/js/66.4025be6c.js"><link rel="prefetch" href="/assets/js/67.6380cfaa.js"><link rel="prefetch" href="/assets/js/68.3588b4aa.js"><link rel="prefetch" href="/assets/js/69.2c852af5.js"><link rel="prefetch" href="/assets/js/70.c39a2085.js"><link rel="prefetch" href="/assets/js/71.2e389b5c.js"><link rel="prefetch" href="/assets/js/72.df2ca1e5.js"><link rel="prefetch" href="/assets/js/73.422aecbb.js"><link rel="prefetch" href="/assets/js/74.f19ba0d3.js"><link rel="prefetch" href="/assets/js/75.746eb65e.js"><link rel="prefetch" href="/assets/js/76.d4715a8f.js"><link rel="prefetch" href="/assets/js/77.91d6b684.js"><link rel="prefetch" href="/assets/js/78.48b24d11.js"><link rel="prefetch" href="/assets/js/79.f58fb4ff.js"><link rel="prefetch" href="/assets/js/8.617b6635.js"><link rel="prefetch" href="/assets/js/80.c7d117ae.js"><link rel="prefetch" href="/assets/js/81.a91a687d.js"><link rel="prefetch" href="/assets/js/82.2d7638a8.js"><link rel="prefetch" href="/assets/js/83.bdec5155.js"><link rel="prefetch" href="/assets/js/84.74ad212c.js"><link rel="prefetch" href="/assets/js/85.d0ae7714.js"><link rel="prefetch" href="/assets/js/86.242198ca.js"><link rel="prefetch" href="/assets/js/87.07574cc0.js"><link rel="prefetch" href="/assets/js/88.37a810c7.js"><link rel="prefetch" href="/assets/js/89.782ac691.js"><link rel="prefetch" href="/assets/js/9.cf1faa69.js"><link rel="prefetch" href="/assets/js/90.43869112.js"><link rel="prefetch" href="/assets/js/91.801bdf4f.js"><link rel="prefetch" href="/assets/js/92.8268da0d.js"><link rel="prefetch" href="/assets/js/93.4fc1e61d.js"><link rel="prefetch" href="/assets/js/94.e843effd.js"><link rel="prefetch" href="/assets/js/95.3a1dd8dd.js"><link rel="prefetch" href="/assets/js/96.0887bd7f.js"><link rel="prefetch" href="/assets/js/97.53ff243b.js"><link rel="prefetch" href="/assets/js/98.b4e93782.js"><link rel="prefetch" href="/assets/js/99.68d6af29.js"><link rel="prefetch" href="/assets/js/vendors~docsearch.c040f9c6.js">
    <link rel="stylesheet" href="/assets/css/0.styles.f6912c97.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container" data-v-7dd95ae2><div data-v-7dd95ae2><div class="password-shadow password-wrapper-out" style="display:none;" data-v-59e6cb88 data-v-7dd95ae2 data-v-7dd95ae2><h3 class="title" data-v-59e6cb88>Pika 文档</h3> <p class="description" data-v-59e6cb88> </p> <label id="box" class="inputBox" data-v-59e6cb88><input type="password" value="" data-v-59e6cb88> <span data-v-59e6cb88>Konck! Knock!</span> <button data-v-59e6cb88>OK</button></label> <div class="footer" data-v-59e6cb88><span data-v-59e6cb88><i class="iconfont reco-theme" data-v-59e6cb88></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-59e6cb88>vuePress-theme-reco</a></span> <span data-v-59e6cb88><i class="iconfont reco-copyright" data-v-59e6cb88></i> <a data-v-59e6cb88><span data-v-59e6cb88>Pika</span>
          
        <span data-v-59e6cb88>2015 - </span>
        2024
      </a></span></div></div> <div class="hide" data-v-7dd95ae2><header class="navbar" data-v-7dd95ae2><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/pika-smalllogo.png" alt="Pika 文档" class="logo"> <span class="site-name">Pika 文档</span></a> <div class="links"><!----> <div class="search-box"><i class="iconfont reco-search"></i> <input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link"><i class="undefined"></i>
  首页
</a></div><div class="nav-item"><a href="/document/Pika介绍.html" class="nav-link"><i class="undefined"></i>
  文档
</a></div><div class="nav-item"><a href="https://github.com/OpenAtomFoundation/pika" target="_blank" rel="noopener noreferrer" class="nav-link external"><i></i>
  文档仓库
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav></div></header> <div class="sidebar-mask" data-v-7dd95ae2></div> <aside class="sidebar" data-v-7dd95ae2><div class="personal-info-wrapper" data-v-1fad0c41 data-v-7dd95ae2><!----> <h3 class="name" data-v-1fad0c41>
    Pika
  </h3> <div class="num" data-v-1fad0c41><div data-v-1fad0c41><h3 data-v-1fad0c41>67</h3> <h6 data-v-1fad0c41>Articles</h6></div> <div data-v-1fad0c41><h3 data-v-1fad0c41>0</h3> <h6 data-v-1fad0c41>Tags</h6></div></div> <ul class="social-links" data-v-1fad0c41></ul> <hr data-v-1fad0c41></div> <nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link"><i class="undefined"></i>
  首页
</a></div><div class="nav-item"><a href="/document/Pika介绍.html" class="nav-link"><i class="undefined"></i>
  文档
</a></div><div class="nav-item"><a href="https://github.com/OpenAtomFoundation/pika" target="_blank" rel="noopener noreferrer" class="nav-link external"><i></i>
  文档仓库
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav> <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><a href="/document/Pika介绍" class="sidebar-heading clickable"><span>概况</span> <!----></a> <ul class="sidebar-links sidebar-group-items"><li><a href="/document/Pika介绍.html" class="sidebar-link">Pika介绍</a></li><li><a href="/document/use/支持的语言和客户端.html" class="sidebar-link">支持的语言和客户端</a></li><li><a href="/document/use/当前支持的Redis接口以及兼容情况.html" class="sidebar-link">支持的Redis接口</a></li><li><a href="/document/FAQ.html" class="sidebar-link">FAQ</a></li></ul></section></li><li><section class="sidebar-group depth-0"><a href="/document/use/安装使用" class="sidebar-heading clickable"><span>使用与运维</span> <!----></a> <ul class="sidebar-links sidebar-group-items"><li><a href="/document/use/安装使用.html" class="sidebar-link">安装使用</a></li><li><a href="/document/use/配置文件说明.html" class="sidebar-link">配置文件</a></li><li><a href="/document/use/数据目录说明.html" class="sidebar-link">数据目录</a></li><li><a href="/document/use/info信息说明.html" class="sidebar-link">info信息</a></li><li><a href="/document/use/部分管理指令说明.html" class="sidebar-link">管理指令</a></li><li><a href="/document/use/差异化命令.html" class="sidebar-link">差异化命令</a></li><li><a href="/document/use/Pika订阅.html" class="sidebar-link">Pika订阅</a></li><li><a href="/document/use/配合sentinel实现pika自动容灾.html" class="sidebar-link">自动容灾</a></li><li><a href="/document/use/Pika多库版命令.html" class="sidebar-link">多库版命令</a></li><li><a href="/document/use/Pika分片.html" class="sidebar-link">分片教程</a></li><li><a href="/document/use/副本一致性使用说明.html" class="sidebar-link">副本一致性</a></li><li><a href="/document/use/Pika最佳实践.html" class="sidebar-link">最佳实践</a></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><a href="/document/use/如何实现3.3.6升级到3.5.x" class="sidebar-heading clickable"><span>升级指南</span> <span class="arrow right"></span></a> <!----></section></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>性能与优化</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/document/performance/3.2.x性能.html" class="sidebar-link">3.2.x性能</a></li><li><a href="/document/use/Pika内存使用.html" class="sidebar-link">Pika内存使用</a></li><li><a href="/document/performance/Redis与Pikascan性能对比.html" class="sidebar-link">Redis 与 Pika scan 性能对比</a></li><li><a href="/document/performance/Pika3.5参数优化手册.html" class="sidebar-link">Pika 3.5 参数优化手册</a></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><p class="sidebar-heading"><span>Pika 优化案例</span> <span class="arrow right"></span></p> <!----></section></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>设计与实现</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/document/design/整体架构.html" class="sidebar-link">整体架构</a></li><li><a href="/document/design/线程模型.html" class="sidebar-link">线程模型</a></li><li><a href="/document/design/锁的应用.html" class="sidebar-link">锁的应用</a></li><li><a href="/document/design/全同步.html" class="sidebar-link">全同步</a></li><li><a href="/document/design/增量同步.html" class="sidebar-link">增量同步</a></li><li><a href="/document/design/pika主从同步原理.html" class="active sidebar-link">主从同步</a></li><li><a href="/document/design/副本一致性.html" class="sidebar-link">副本一致性</a></li><li><a href="/document/design/pika在codis中的探索.html" class="sidebar-link">Pika 与 Codis</a></li><li><a href="/document/design/快照式备份.html" class="sidebar-link">快照式备份</a></li><li><a href="/document/design/pika-NoSQL原理概述.html" class="sidebar-link">NoSQL 实现</a></li><li><a href="/document/design/blackwidow存储引擎数据格式.html" class="sidebar-link">旧存储结构</a></li><li><a href="/document/design/Pika新存储结构Floyd.html" class="sidebar-link">新存储结构 Floyd</a></li><li><a href="/document/design/floyd存储方案.html" class="sidebar-link">Floyd 详解</a></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><a href="/document/design/Pika源码学习study1" class="sidebar-heading clickable"><span>Pika 源码学习</span> <span class="arrow right"></span></a> <!----></section></li></ul></section></li><li><section class="sidebar-group depth-0"><a href="/document/develop/Pikacodingstyle" class="sidebar-heading clickable"><span>开发文档</span> <!----></a> <ul class="sidebar-links sidebar-group-items"><li><a href="/document/develop/Pikacodingstyle.html" class="sidebar-link">Pika 开发规范</a></li><li><a href="/document/develop/pikacode.html" class="sidebar-link">Pika 代码梳理</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>更新日志</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><section class="sidebar-group collapsable is-sub-group depth-1"><a href="/document/history/Pika_v3.5.2" class="sidebar-heading clickable open"><span>版本日志</span> <span class="arrow down"></span></a> <ul class="sidebar-links sidebar-group-items"><li><a href="/document/history/Pika_v3.5.2.html" class="sidebar-link">What's new in Pika v3.5.2</a></li><li><a href="/document/history/Pika_v3.5.1.html" class="sidebar-link">What's new in Pika v3.5.1</a></li><li><a href="/document/history/Pika_v3.5.0.html" class="sidebar-link">What's new in Pika v3.5.0</a></li></ul></section></li><li><section class="sidebar-group collapsable is-sub-group depth-1"><a href="/document/weekly/20231201周会纪要" class="sidebar-heading clickable"><span>周会纪要</span> <span class="arrow right"></span></a> <!----></section></li></ul></section></li><li><section class="sidebar-group depth-0"><a href="/document/Pika动态" class="sidebar-heading clickable"><span>项目资讯</span> <!----></a> <ul class="sidebar-links sidebar-group-items"><li><a href="/document/Pika动态.html" class="sidebar-link">Pika 公告栏</a></li><li><a href="/document/项目支持.html" class="sidebar-link">项目支持</a></li><li><a href="/document/未来规划.html" class="sidebar-link">未来规划</a></li><li><a href="/document/社区贡献文档.html" class="sidebar-link">社区贡献文档</a></li></ul></section></li><li><section class="sidebar-group depth-0"><a href="/tool/3.2.新旧可读三类binlog转换工具" class="sidebar-heading clickable"><span>工具包</span> <!----></a> <ul class="sidebar-links sidebar-group-items"><li><a href="/document/tool/3.2.新旧可读三类binlog转换工具.html" class="sidebar-link">3.2.新，旧，可读三类binlog转换工具</a></li><li><a href="/document/tool/根据时间戳恢复数据工具.html" class="sidebar-link">根据时间戳恢复数据工具</a></li><li><a href="/document/tool/Redis到Pika迁移工具.html" class="sidebar-link">Redis到Pika迁移工具</a></li><li><a href="/document/tool/Redis请求实时copy到Pika工具.html" class="sidebar-link">Redis请求实时copy到Pika工具</a></li><li><a href="/document/tool/Pikatool1.html" class="sidebar-link">Pika到Pika、Redis迁移工具 Pika-Port(适用于 Pika v2.x&amp;v3.0.x)</a></li><li><a href="/document/tool/Pikatool2.html" class="sidebar-link">Pika到Pika、Redis迁移工具 Pika-Migrage(适用于 Pika v3.2及以上版本)</a></li><li><a href="/document/tool/Pika的kv数据写入txt文本工具.html" class="sidebar-link">Pika的kv数据写入txt文本工具</a></li><li><a href="/document/tool/kv数据txt文本迁移Pika工具.html" class="sidebar-link">kv数据txt文本迁移Pika工具</a></li><li><a href="/document/tool/pikaexporter监控工具.html" class="sidebar-link">pika exporter监控工具</a></li><li><a href="/document/tool/codis-redis实时同步pika工具.html" class="sidebar-link">codis-redis实时同步pika工具</a></li></ul></section></li></ul> </aside> <div class="password-shadow password-wrapper-in" style="display:none;" data-v-59e6cb88 data-v-7dd95ae2><h3 class="title" data-v-59e6cb88>pika主从同步原理</h3> <!----> <label id="box" class="inputBox" data-v-59e6cb88><input type="password" value="" data-v-59e6cb88> <span data-v-59e6cb88>Konck! Knock!</span> <button data-v-59e6cb88>OK</button></label> <div class="footer" data-v-59e6cb88><span data-v-59e6cb88><i class="iconfont reco-theme" data-v-59e6cb88></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-59e6cb88>vuePress-theme-reco</a></span> <span data-v-59e6cb88><i class="iconfont reco-copyright" data-v-59e6cb88></i> <a data-v-59e6cb88><span data-v-59e6cb88>Pika</span>
          
        <span data-v-59e6cb88>2015 - </span>
        2024
      </a></span></div></div> <div data-v-7dd95ae2><div data-v-7dd95ae2><main class="page"><section style="display:;"><div class="page-title"><h1 class="title">pika主从同步原理</h1> <div data-v-8a445198><i class="iconfont reco-account" data-v-8a445198><span data-v-8a445198>Pika</span></i> <!----> <!----> <!----></div></div> <div class="theme-reco-content content__default"><h2 id="pika主从同步"><a href="#pika主从同步" class="header-anchor">#</a> pika主从同步</h2> <p>主要为了分析探索一下pika是如何实现主从同步的，pika的主从同步的原理与redis的同步方案还不相同，本文主要是为了分析其主从同步的相关流程（pika基于3.4版本）。</p> <h2 id="pika主从同步原理"><a href="#pika主从同步原理" class="header-anchor">#</a> pika主从同步原理</h2> <p>主从同步的原理，主要是通过在启动的时候启动了两部分的线程来进行的。</p> <ul><li>auxiliary_thread线程</li> <li>pika_rm中的pika_repl_client线程池和pika_repl_server线程池</li></ul> <p>先逐个分析一下两个部分线程的工作的流程。</p> <h3 id="auxiliary-thread线程"><a href="#auxiliary-thread线程" class="header-anchor">#</a> auxiliary_thread线程</h3> <p>在pika的pika_server的Start函数中启动了auxiliary_thread线程。</p> <div class="language-c++ extra-class"><pre class="language-text"><code>  ret = pika_auxiliary_thread_-&gt;StartThread();
  if (ret != pink::kSuccess) {
    tables_.clear();
    LOG(FATAL) &lt;&lt; &quot;Start Auxiliary Thread Error: &quot; &lt;&lt; ret &lt;&lt; (ret == pink::kCreateThreadError ? &quot;: create thread error &quot; : &quot;: other error&quot;);
  }
</code></pre></div><p>此时启动的线程就是位于pika_auxiliary_thread.cc中的线程函数。</p> <div class="language-c++ extra-class"><pre class="language-text"><code>void* PikaAuxiliaryThread::ThreadMain() {
  while (!should_stop()) {            //  是否停止线程
    if (g_pika_conf-&gt;classic_mode()) {    // 判断当前运行的模式是分布式模式还是经典模式
      if (g_pika_server-&gt;ShouldMetaSync()) {
        g_pika_rm-&gt;SendMetaSyncRequest();
      } else if (g_pika_server-&gt;MetaSyncDone()) {
        g_pika_rm-&gt;RunSyncSlavePartitionStateMachine();
      }
    } else {
      g_pika_rm-&gt;RunSyncSlavePartitionStateMachine();  // 分布式模式则直接启动状态机的同步
    }

    Status s = g_pika_rm-&gt;CheckSyncTimeout(slash::NowMicros());  // 检查超时的节点
    if (!s.ok()) {
      LOG(WARNING) &lt;&lt; s.ToString();
    }

    // TODO(whoiami) timeout
    s = g_pika_server-&gt;TriggerSendBinlogSync();     // 触发binlog的主从同步
    if (!s.ok()) {
      LOG(WARNING) &lt;&lt; s.ToString();
    }
    // send to peer
    int res = g_pika_server-&gt;SendToPeer();   // 将待发送的任务加入到工作线程队列中
    if (!res) {
      // sleep 100 ms
      mu_.Lock();
      cv_.TimedWait(100);
      mu_.Unlock();
    } else {
      //LOG_EVERY_N(INFO, 1000) &lt;&lt; &quot;Consume binlog number &quot; &lt;&lt; res;
    }
  }
  return NULL;
}
</code></pre></div><h4 id="runsyncslavepartitionstatemachine"><a href="#runsyncslavepartitionstatemachine" class="header-anchor">#</a> RunSyncSlavePartitionStateMachine-</h4> <p>该函数就是处理主从同步过程中的状态机，根据不同的状态去进行不同的操作。</p> <div class="language-c++ extra-class"><pre class="language-text"><code>Status PikaReplicaManager::RunSyncSlavePartitionStateMachine() {
  slash::RWLock l(&amp;partitions_rw_, false);
  for (const auto&amp; item : sync_slave_partitions_) {   // 获取所有的从节点同步信息
    PartitionInfo p_info = item.first;
    std::shared_ptr&lt;SyncSlavePartition&gt; s_partition = item.second;
    if (s_partition-&gt;State() == ReplState::kTryConnect) {   // 如果同步的信息是kTryConnect则发送TrySync的同步请求
      LOG(WARNING) &lt;&lt; &quot;Partition start, Table Name: &quot;
          &lt;&lt; p_info.table_name_ &lt;&lt; &quot; Partition Id: &quot; &lt;&lt; p_info.partition_id_;
      SendPartitionTrySyncRequest(p_info.table_name_, p_info.partition_id_);
    } else if (s_partition-&gt;State() == ReplState::kTryDBSync) {  // 如果是kTryDB的状态则发送DB同步的请求
      SendPartitionDBSyncRequest(p_info.table_name_, p_info.partition_id_);
    } else if (s_partition-&gt;State() == ReplState::kWaitReply) {  // 如果是wait状态则什么都不做
      continue;
    } else if (s_partition-&gt;State() == ReplState::kWaitDBSync) {  // 如果是waitdb状态则等待
      std::shared_ptr&lt;Partition&gt; partition =
          g_pika_server-&gt;GetTablePartitionById(
                  p_info.table_name_, p_info.partition_id_);
      if (partition) {
        partition-&gt;TryUpdateMasterOffset();   // 更新和主之间的offset
      } else {
        LOG(WARNING) &lt;&lt; &quot;Partition not found, Table Name: &quot;
          &lt;&lt; p_info.table_name_ &lt;&lt; &quot; Partition Id: &quot; &lt;&lt; p_info.partition_id_;
      }
    } else if (s_partition-&gt;State() == ReplState::kConnected
      || s_partition-&gt;State() == ReplState::kNoConnect
      || s_partition-&gt;State() == ReplState::kDBNoConnect) {  // 如果是已连接或者失联则什么都不处理
      continue;
    }
  }
  return Status::OK();
}
</code></pre></div><p>从状态机的运行来看，所有的步骤都是依赖于该函数通过状态来驱动进行不同的操作。</p> <h4 id="checksynctimeout-检查连接的超时时间"><a href="#checksynctimeout-检查连接的超时时间" class="header-anchor">#</a> CheckSyncTimeout-检查连接的超时时间</h4> <div class="language-c++ extra-class"><pre class="language-text"><code>Status PikaReplicaManager::CheckSyncTimeout(uint64_t now) {
  slash::RWLock l(&amp;partitions_rw_, false);

  for (auto&amp; iter : sync_master_partitions_) {
    std::shared_ptr&lt;SyncMasterPartition&gt; partition = iter.second;
    Status s = partition-&gt;CheckSyncTimeout(now);  // 获取所有的master的同步节点检查是否超时
    if (!s.ok()) {
      LOG(WARNING) &lt;&lt; &quot;CheckSyncTimeout Failed &quot; &lt;&lt; s.ToString();
    }
  }
  for (auto&amp; iter : sync_slave_partitions_) {
    std::shared_ptr&lt;SyncSlavePartition&gt; partition = iter.second;
    Status s = partition-&gt;CheckSyncTimeout(now);  // 获取所有slave的同步节点信息检查是否超时
    if (!s.ok()) {
      LOG(WARNING) &lt;&lt; &quot;CheckSyncTimeout Failed &quot; &lt;&lt; s.ToString();
    }
  }
  return Status::OK();
}
</code></pre></div><p>主要是检查master和slave的同步连接信息是否超时。</p> <div class="language-c++ extra-class"><pre class="language-text"><code>Status SyncMasterPartition::CheckSyncTimeout(uint64_t now) {
  std::unordered_map&lt;std::string, std::shared_ptr&lt;SlaveNode&gt;&gt; slaves = GetAllSlaveNodes();

  std::vector&lt;Node&gt; to_del;
  for (auto&amp; slave_iter : slaves) {
    std::shared_ptr&lt;SlaveNode&gt; slave_ptr = slave_iter.second;   // 获取所有slave的连接信息
    slash::MutexLock l(&amp;slave_ptr-&gt;slave_mu);
    if (slave_ptr-&gt;LastRecvTime() + kRecvKeepAliveTimeout &lt; now) {  // 如果最后的时间超时则删除该连接
      to_del.push_back(Node(slave_ptr-&gt;Ip(), slave_ptr-&gt;Port()));
    } else if (slave_ptr-&gt;LastSendTime() + kSendKeepAliveTimeout &lt; now &amp;&amp; slave_ptr-&gt;sent_offset == slave_ptr-&gt;acked_offset) {  // 如果最后的发送时间未超时 并且主从同步的偏移量发送的与回复的相同则发送binlogchips请求并且更新当前的最后发送时间
      std::vector&lt;WriteTask&gt; task;
      RmNode rm_node(slave_ptr-&gt;Ip(), slave_ptr-&gt;Port(), slave_ptr-&gt;TableName(), slave_ptr-&gt;PartitionId(), slave_ptr-&gt;SessionId());
      WriteTask empty_task(rm_node, BinlogChip(LogOffset(), &quot;&quot;), LogOffset());
      task.push_back(empty_task);
      Status s = g_pika_rm-&gt;SendSlaveBinlogChipsRequest(slave_ptr-&gt;Ip(), slave_ptr-&gt;Port(), task);    // 同步当前的主从同步的信息
      slave_ptr-&gt;SetLastSendTime(now);
      if (!s.ok()) {
        LOG(INFO)&lt;&lt; &quot;Send ping failed: &quot; &lt;&lt; s.ToString();
        return Status::Corruption(&quot;Send ping failed: &quot; + slave_ptr-&gt;Ip() + &quot;:&quot; + std::to_string(slave_ptr-&gt;Port()));
      }
    }
  }

  for (auto&amp; node : to_del) {  // 将超时的连接信息都删除掉
    coordinator_.SyncPros().RemoveSlaveNode(node.Ip(), node.Port());
    g_pika_rm-&gt;DropItemInWriteQueue(node.Ip(), node.Port());
    LOG(WARNING) &lt;&lt; SyncPartitionInfo().ToString() &lt;&lt; &quot; Master del Recv Timeout slave success &quot; &lt;&lt; node.ToString();
  }
  return Status::OK();
}
</code></pre></div><p>主节点主要维护了当前的一些主从连接的信息维护。</p> <div class="language-c++ extra-class"><pre class="language-text"><code>Status SyncSlavePartition::CheckSyncTimeout(uint64_t now) {
  slash::MutexLock l(&amp;partition_mu_);
  // no need to do session keepalive return ok
  if (repl_state_ != ReplState::kWaitDBSync &amp;&amp; repl_state_ != ReplState::kConnected) {
    return Status::OK();  // 如果从节点的信息不是waitdb或者连接状态则返回ok
  }
  if (m_info_.LastRecvTime() + kRecvKeepAliveTimeout &lt; now) {
    // update slave state to kTryConnect, and try reconnect to master node
    repl_state_ = ReplState::kTryConnect;
    g_pika_server-&gt;SetLoopPartitionStateMachine(true);  // 否则就设置成tryconnect状态去尝试连接主节点
  }
  return Status::OK();
}
</code></pre></div><h4 id="triggersendbinlogsync-生成每个节点待发送的数据任务"><a href="#triggersendbinlogsync-生成每个节点待发送的数据任务" class="header-anchor">#</a> TriggerSendBinlogSync-生成每个节点待发送的数据任务</h4> <div class="language-c++ extra-class"><pre class="language-text"><code>Status PikaServer::TriggerSendBinlogSync() {
  return g_pika_rm-&gt;WakeUpBinlogSync();
}

...

Status PikaReplicaManager::WakeUpBinlogSync() {
  slash::RWLock l(&amp;partitions_rw_, false);
  for (auto&amp; iter : sync_master_partitions_) {
    std::shared_ptr&lt;SyncMasterPartition&gt; partition = iter.second;
    Status s = partition-&gt;WakeUpSlaveBinlogSync(); // 检查每个节点是否需要生成binlog同步任务
    if (!s.ok()) {
      return s;
    }
  }
  return Status::OK();
}
</code></pre></div><p>主要是检查每个连接的从节点信息是否需要生成同步binlog任务。</p> <div class="language-c++ extra-class"><pre class="language-text"><code>Status SyncMasterPartition::WakeUpSlaveBinlogSync() {
  std::unordered_map&lt;std::string, std::shared_ptr&lt;SlaveNode&gt;&gt; slaves = GetAllSlaveNodes();
  std::vector&lt;std::shared_ptr&lt;SlaveNode&gt;&gt; to_del;
  for (auto&amp; slave_iter : slaves) {
    std::shared_ptr&lt;SlaveNode&gt; slave_ptr = slave_iter.second;
    slash::MutexLock l(&amp;slave_ptr-&gt;slave_mu);
    if (slave_ptr-&gt;sent_offset == slave_ptr-&gt;acked_offset) {  // 检查当前同步的数据信息是否跟回复的数据偏移相同
      Status s = ReadBinlogFileToWq(slave_ptr);  // 写binlog任务到该从节点连接上面
      if (!s.ok()) {
        to_del.push_back(slave_ptr);
        LOG(WARNING) &lt;&lt; &quot;WakeUpSlaveBinlogSync falied, Delete from RM, slave: &quot; &lt;&lt;
          slave_ptr-&gt;ToStringStatus() &lt;&lt; &quot; &quot; &lt;&lt; s.ToString();
      }
    }
  }
  for (auto&amp; to_del_slave : to_del) {  // 如果同步失败则删除该node
    RemoveSlaveNode(to_del_slave-&gt;Ip(), to_del_slave-&gt;Port());
  }
  return Status::OK();
}
</code></pre></div><p>其中ReadBinlogFileToWq就是根据当前的连接来生成binlog同步任务。</p> <div class="language-c++ extra-class"><pre class="language-text"><code>Status SyncMasterPartition::ReadBinlogFileToWq(const std::shared_ptr&lt;SlaveNode&gt;&amp; slave_ptr) {
  int cnt = slave_ptr-&gt;sync_win.Remaining();
  std::shared_ptr&lt;PikaBinlogReader&gt; reader = slave_ptr-&gt;binlog_reader;  //获取当前binlogreader
  if (reader == nullptr) {
    return Status::OK();
  }
  std::vector&lt;WriteTask&gt; tasks;
  for (int i = 0; i &lt; cnt; ++i) {
    std::string msg;
    uint32_t filenum;
    uint64_t offset;
    if (slave_ptr-&gt;sync_win.GetTotalBinlogSize() &gt; PIKA_MAX_CONN_RBUF_HB * 2) {
      LOG(INFO) &lt;&lt; slave_ptr-&gt;ToString() &lt;&lt; &quot; total binlog size in sync window is :&quot;
                &lt;&lt; slave_ptr-&gt;sync_win.GetTotalBinlogSize();
      break;  //检查当前同步窗口的大小
    }
    Status s = reader-&gt;Get(&amp;msg, &amp;filenum, &amp;offset);  //获取对应的偏移数据
    if (s.IsEndFile()) {
      break;
    } else if (s.IsCorruption() || s.IsIOError()) {
      LOG(WARNING) &lt;&lt; SyncPartitionInfo().ToString()
        &lt;&lt; &quot; Read Binlog error : &quot; &lt;&lt; s.ToString();
      return s;
    }
    BinlogItem item;
    if (!PikaBinlogTransverter::BinlogItemWithoutContentDecode(
          TypeFirst, msg, &amp;item)) {
      LOG(WARNING) &lt;&lt; &quot;Binlog item decode failed&quot;;
      return Status::Corruption(&quot;Binlog item decode failed&quot;);
    }
    BinlogOffset sent_b_offset = BinlogOffset(filenum, offset);   // 生成发送的偏移量
    LogicOffset sent_l_offset = LogicOffset(item.term_id(), item.logic_id());
    LogOffset sent_offset(sent_b_offset, sent_l_offset);

    slave_ptr-&gt;sync_win.Push(SyncWinItem(sent_offset, msg.size()));  //设置同步窗口的大小
    slave_ptr-&gt;SetLastSendTime(slash::NowMicros());   //设置最后的发送时间
    RmNode rm_node(slave_ptr-&gt;Ip(), slave_ptr-&gt;Port(), slave_ptr-&gt;TableName(), slave_ptr-&gt;PartitionId(), slave_ptr-&gt;SessionId());
    WriteTask task(rm_node, BinlogChip(sent_offset, msg), slave_ptr-&gt;sent_offset);
    tasks.push_back(task);  // 包装成任务
    slave_ptr-&gt;sent_offset = sent_offset;  // 设置当前的发送偏移量
  }

  if (!tasks.empty()) {
    g_pika_rm-&gt;ProduceWriteQueue(slave_ptr-&gt;Ip(), slave_ptr-&gt;Port(), partition_info_.partition_id_, tasks);  // 将任务放入队列中等待处理
  }
  return Status::OK();
}
</code></pre></div><p>主要就是通过获取偏移量，然后生成任务并放入发送队列中等待处理。</p> <h4 id="sendtopeer-将待发送的binlog同步任务发送给从节点"><a href="#sendtopeer-将待发送的binlog同步任务发送给从节点" class="header-anchor">#</a> SendToPeer-将待发送的binlog同步任务发送给从节点</h4> <div class="language-c++ extra-class"><pre class="language-text"><code>int PikaServer::SendToPeer() {
  return g_pika_rm-&gt;ConsumeWriteQueue();
}

...
  
int PikaReplicaManager::ConsumeWriteQueue() {
  std::unordered_map&lt;std::string, std::vector&lt;std::vector&lt;WriteTask&gt;&gt;&gt; to_send_map;
  int counter = 0;
  {
    slash::MutexLock l(&amp;write_queue_mu_);
    for (auto&amp; iter : write_queues_) {
      const std::string&amp; ip_port = iter.first;
      std::unordered_map&lt;uint32_t, std::queue&lt;WriteTask&gt;&gt;&amp; p_map = iter.second; //获取队列
      for (auto&amp; partition_queue : p_map) {
        std::queue&lt;WriteTask&gt;&amp; queue = partition_queue.second;
        for (int i = 0; i &lt; kBinlogSendPacketNum; ++i) {
          if (queue.empty()) {
            break;
          }
          size_t batch_index = queue.size() &gt; kBinlogSendBatchNum ? kBinlogSendBatchNum : queue.size();   // 检查当前可发送的大小
          std::vector&lt;WriteTask&gt; to_send;
          int batch_size = 0;
          for (size_t i = 0; i &lt; batch_index; ++i) {
            WriteTask&amp; task = queue.front();
            batch_size +=  task.binlog_chip_.binlog_.size();
            // make sure SerializeToString will not over 2G
            if (batch_size &gt; PIKA_MAX_CONN_RBUF_HB) {
              break;
            }
            to_send.push_back(task);  // 放入可发送的队列中
            queue.pop();
            counter++;
          }
          if (!to_send.empty()) {
            to_send_map[ip_port].push_back(std::move(to_send));
          }
        }
      }
    }
  }

  std::vector&lt;std::string&gt; to_delete;
  for (auto&amp; iter : to_send_map) {
    std::string ip;
    int port = 0;
    if (!slash::ParseIpPortString(iter.first, ip, port)) {
      LOG(WARNING) &lt;&lt; &quot;Parse ip_port error &quot; &lt;&lt; iter.first;
      continue;
    }
    for (auto&amp; to_send : iter.second) {
      Status s = pika_repl_server_-&gt;SendSlaveBinlogChips(ip, port, to_send); // 发送Binglog任务
      if (!s.ok()) {
        LOG(WARNING) &lt;&lt; &quot;send binlog to &quot; &lt;&lt; ip &lt;&lt; &quot;:&quot; &lt;&lt; port &lt;&lt; &quot; failed, &quot; &lt;&lt; s.ToString();
        to_delete.push_back(iter.first);  // 如果发送失败则放入失败队列中
        continue;
      }
    }
  }

  if (!to_delete.empty()) {
    {
      slash::MutexLock l(&amp;write_queue_mu_);
      for (auto&amp; del_queue : to_delete) {
        write_queues_.erase(del_queue);  //删除发送失败的任务
      }
    }
  }
  return counter;
}
</code></pre></div><p>最终通过pika_repl_server_的SendSlaveBinlogChip<a href="https://so.csdn.net/so/search?q=s%E5%87%BD%E6%95%B0&amp;spm=1001.2101.3001.7020" target="_blank" rel="noopener noreferrer">s函数<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>将当前待发送的任务发送出去。</p> <h3 id="pika-repl-client和pika-repl-server-线程"><a href="#pika-repl-client和pika-repl-server-线程" class="header-anchor">#</a> pika_repl_client和pika_repl_server_线程</h3> <p>这两个线程就是维护了主从连接的client和server端的交互功能，auxiliary_thread中状态机触发的连接状态就是依赖于这两个线程来完成交互。</p> <h4 id="pika-repl-client客户端连接管理线程"><a href="#pika-repl-client客户端连接管理线程" class="header-anchor">#</a> pika_repl_client客户端连接管理线程</h4> <p>pika_reple_client的最核心的原理就是通过一个基于epoll（linux平台）的事件驱动，去完成多个连接的事件驱动，并通过加入线程池来提供epoll的处理性能。接下来就大致了解一下pika_repl_client完成的交互的相关功能。</p> <p>在主从同步过程中，无论是pika_repl_client还是pika_repl_server_底层都利用了pink库的PbConn模式来进行的数据交互。</p> <p>通过client_thread的逻辑流程来简单分析一下PbConn的执行流程。</p> <p>在PikaReplClient的Start流程中，启动了如下线程。</p> <div class="language-c++ extra-class"><pre class="language-text"><code>int PikaReplClient::Start() {
  int res = client_thread_-&gt;StartThread();   // 启动一个epoll的事件驱动
  if (res != pink::kSuccess) {
    LOG(FATAL) &lt;&lt; &quot;Start ReplClient ClientThread Error: &quot; &lt;&lt; res &lt;&lt; (res == pink::kCreateThreadError ? &quot;: create thread error &quot; : &quot;: other error&quot;);
  }
  for (size_t i = 0; i &lt; bg_workers_.size(); ++i) {  // 通过将epoll事件驱动的执行分发到线程池中执行
    res = bg_workers_[i]-&gt;StartThread();
    if (res != pink::kSuccess) {
      LOG(FATAL) &lt;&lt; &quot;Start Pika Repl Worker Thread Error: &quot; &lt;&lt; res
        &lt;&lt; (res == pink::kCreateThreadError ? &quot;: create thread error &quot; : &quot;: other error&quot;);
    }
  }
  return res;
}
</code></pre></div><p>此时client_thread启动的就是位于pink的client_thread.c中的ClientThread线程。</p> <div class="language-c++ extra-class"><pre class="language-text"><code>void *ClientThread::ThreadMain() {
  int nfds = 0;
  PinkFiredEvent *pfe = NULL;

  struct timeval when;
  gettimeofday(&amp;when, NULL);
  struct timeval now = when;

  when.tv_sec += (cron_interval_ / 1000);
  when.tv_usec += ((cron_interval_ % 1000) * 1000);
  int timeout = cron_interval_;
  if (timeout &lt;= 0) {
    timeout = PINK_CRON_INTERVAL;
  }

  std::string ip_port;

  while (!should_stop()) {
    if (cron_interval_ &gt; 0) {
      gettimeofday(&amp;now, nullptr);
      if (when.tv_sec &gt; now.tv_sec ||
          (when.tv_sec == now.tv_sec &amp;&amp; when.tv_usec &gt; now.tv_usec)) {
        timeout = (when.tv_sec - now.tv_sec) * 1000 +
          (when.tv_usec - now.tv_usec) / 1000;
      } else {
        // do user defined cron
        handle_-&gt;CronHandle();   // 执行定时任务

        DoCronTask();
        when.tv_sec = now.tv_sec + (cron_interval_ / 1000);
        when.tv_usec = now.tv_usec + ((cron_interval_ % 1000) * 1000);
        timeout = cron_interval_;
      }
    }
    //{
    //InternalDebugPrint();
    //}
    nfds = pink_epoll_-&gt;PinkPoll(timeout);  //事件驱动
    for (int i = 0; i &lt; nfds; i++) {
      pfe = (pink_epoll_-&gt;firedevent()) + i;
      if (pfe == NULL) {
        continue;
      }

      if (pfe-&gt;fd == pink_epoll_-&gt;notify_receive_fd()) {  // 处理驱动
        ProcessNotifyEvents(pfe);
        continue;
      }

      int should_close = 0;
      std::map&lt;int, std::shared_ptr&lt;PinkConn&gt;&gt;::iterator iter = fd_conns_.find(pfe-&gt;fd);
      if (iter == fd_conns_.end()) {
        log_info(&quot;fd %d not found in fd_conns\n&quot;, pfe-&gt;fd);
        pink_epoll_-&gt;PinkDelEvent(pfe-&gt;fd);
        continue;
      }

      std::shared_ptr&lt;PinkConn&gt; conn = iter-&gt;second;

      if (connecting_fds_.count(pfe-&gt;fd)) {
        Status s = ProcessConnectStatus(pfe, &amp;should_close);
        if (!s.ok()) {
          handle_-&gt;DestConnectFailedHandle(conn-&gt;ip_port(), s.ToString());
        }
        connecting_fds_.erase(pfe-&gt;fd);
      }

      if (!should_close &amp;&amp; (pfe-&gt;mask &amp; EPOLLOUT) &amp;&amp; conn-&gt;is_reply()) {
        WriteStatus write_status = conn-&gt;SendReply();   // 如果当前是可以写数据则调用SendReply
        conn-&gt;set_last_interaction(now);
        if (write_status == kWriteAll) {
          pink_epoll_-&gt;PinkModEvent(pfe-&gt;fd, 0, EPOLLIN);
          conn-&gt;set_is_reply(false);
        } else if (write_status == kWriteHalf) {
          continue;
        } else {
          log_info(&quot;send reply error %d\n&quot;, write_status);
          should_close = 1;
        }
      }

      if (!should_close &amp;&amp; (pfe-&gt;mask &amp; EPOLLIN)) {
        ReadStatus read_status = conn-&gt;GetRequest();  // 如果是接受数据则调用GetRequest来解析
        conn-&gt;set_last_interaction(now);
        if (read_status == kReadAll) {
          // pink_epoll_-&gt;PinkModEvent(pfe-&gt;fd, 0, EPOLLOUT);
        } else if (read_status == kReadHalf) {
          continue;
        } else {
          log_info(&quot;Get request error %d\n&quot;, read_status);
          should_close = 1;
        }
      }

      if ((pfe-&gt;mask &amp; EPOLLERR) || (pfe-&gt;mask &amp; EPOLLHUP) || should_close) {
        {
          log_info(&quot;close connection %d reason %d %d\n&quot;, pfe-&gt;fd, pfe-&gt;mask, should_close);
          pink_epoll_-&gt;PinkDelEvent(pfe-&gt;fd);  // 如果关闭则删除该事件
          CloseFd(conn);
          fd_conns_.erase(pfe-&gt;fd);
          if (ipport_conns_.count(conn-&gt;ip_port())) {
            ipport_conns_.erase(conn-&gt;ip_port());
          }
          if (connecting_fds_.count(conn-&gt;fd())) {
            connecting_fds_.erase(conn-&gt;fd());
          }
        }
      }
    }
  }
  return nullptr;
}
</code></pre></div><p>通过client_thread的执行函数可知，这是一个标准的事件驱动模型。如果可写入则调用conn的SendReply函数，如果是接受事情则调用conn的GetRequest函数。此时的conn就是PbConn。</p> <div class="language-c++ extra-class"><pre class="language-text"><code>// Msg is [ length(COMMAND_HEADER_LENGTH) | body(length bytes) ]
//   step 1. kHeader, we read COMMAND_HEADER_LENGTH bytes;
//   step 2. kPacket, we read header_len bytes;
ReadStatus PbConn::GetRequest() {
  while (true) {
    switch (connStatus_) {
      case kHeader: {
        ssize_t nread = read(
            fd(), rbuf_ + cur_pos_, COMMAND_HEADER_LENGTH - cur_pos_); // 解析头部信息
        if (nread == -1) {
          if (errno == EAGAIN) {
            return kReadHalf;
          } else {
            return kReadError;
          }
        } else if (nread == 0) {
          return kReadClose;
        } else {
          cur_pos_ += nread;
          if (cur_pos_ == COMMAND_HEADER_LENGTH) {
            uint32_t integer = 0;
            memcpy(reinterpret_cast&lt;char*&gt;(&amp;integer),
                   rbuf_, sizeof(uint32_t));
            header_len_ = ntohl(integer);
            remain_packet_len_ = header_len_;
            connStatus_ = kPacket;
            continue;
          }
          return kReadHalf;
        }
      }
      case kPacket: {
        if (header_len_ &gt; rbuf_len_ - COMMAND_HEADER_LENGTH) {  //解析packet
          uint32_t new_size = header_len_ + COMMAND_HEADER_LENGTH;
          if (new_size &lt; kProtoMaxMessage) {
            rbuf_ = reinterpret_cast&lt;char *&gt;(realloc(rbuf_, sizeof(char) * new_size));
            if (rbuf_ == NULL) {
              return kFullError;
            }
            rbuf_len_ = new_size;
            log_info(&quot;Thread_id %ld Expand rbuf to %u, cur_pos_ %u\n&quot;, pthread_self(), new_size, cur_pos_);
          } else {
            return kFullError;
          }
        }
        // read msg body
        ssize_t nread = read(fd(), rbuf_ + cur_pos_, remain_packet_len_);
        if (nread == -1) {
          if (errno == EAGAIN) {
            return kReadHalf;
          } else {
            return kReadError;
          }
        } else if (nread == 0) {
          return kReadClose;
        }
        cur_pos_ += nread;
        remain_packet_len_ -= nread;
        if (remain_packet_len_ == 0) {
          connStatus_ = kComplete;
          continue;
        }
        return kReadHalf;
      }
      case kComplete: {  //解析完成之后调用DealMessage函数来处理
        if (DealMessage() != 0) {
          return kDealError;
        }
        connStatus_ = kHeader;
        cur_pos_ = 0;
        return kReadAll;
      }
      // Add this switch case just for delete compile warning
      case kBuildObuf:
        break;

      case kWriteObuf:
        break;
    }
  }

  return kReadHalf;
}

WriteStatus PbConn::SendReply() {
  ssize_t nwritten = 0;
  size_t item_len;
  slash::MutexLock l(&amp;resp_mu_);
  while (!write_buf_.queue_.empty()) {  //写入的队列是否为空
    std::string item = write_buf_.queue_.front();
    item_len = item.size();
    while (item_len - write_buf_.item_pos_ &gt; 0) {
      nwritten = write(fd(), item.data() + write_buf_.item_pos_, item_len - write_buf_.item_pos_);   // 将数据写入对应的文件描述符
      if (nwritten &lt;= 0) {
        break;
      }
      write_buf_.item_pos_ += nwritten;
      if (write_buf_.item_pos_ == item_len) {
        write_buf_.queue_.pop();
        write_buf_.item_pos_ = 0;
        item_len = 0;
      }
    }
    if (nwritten == -1) {
      if (errno == EAGAIN) {
        return kWriteHalf;
      } else {
        // Here we should close the connection
        return kWriteError;
      }
    }
    if (item_len - write_buf_.item_pos_ != 0) {
      return kWriteHalf;
    }
  }
  return kWriteAll;
}
</code></pre></div><p>从client的事件驱动可知，处理的主要的逻辑函数就是自定义的DealMessage()函数。</p> <p>我们继续分析PikaReplClientConn类。</p> <p>在pika_repl_client_thread.h的定义中。</p> <div class="language-c++ extra-class"><pre class="language-text"><code>class PikaReplClientThread : public pink::ClientThread {
 public:
  PikaReplClientThread(int cron_interval, int keepalive_timeout);
  virtual ~PikaReplClientThread() = default;
  int Start();

 private:
  class ReplClientConnFactory : public pink::ConnFactory {
   public:
    virtual std::shared_ptr&lt;pink::PinkConn&gt; NewPinkConn(
        int connfd,
        const std::string &amp;ip_port,
        pink::Thread *thread,
        void* worker_specific_data,
        pink::PinkEpoll* pink_epoll) const override {
      return std::static_pointer_cast&lt;pink::PinkConn&gt;
        (std::make_shared&lt;PikaReplClientConn&gt;(connfd, ip_port, thread, worker_specific_data, pink_epoll));  // 新连接进来的时候通过初始化成PikaReplClientConn
    }
  };
  class ReplClientHandle : public pink::ClientHandle {
   public:
    void CronHandle() const override {
    }
    void FdTimeoutHandle(int fd, const std::string&amp; ip_port) const override;
    void FdClosedHandle(int fd, const std::string&amp; ip_port) const override;
    bool AccessHandle(std::string&amp; ip) const override {
      // ban 127.0.0.1 if you want to test this routine
      // if (ip.find(&quot;127.0.0.2&quot;) != std::string::npos) {
      //   std::cout &lt;&lt; &quot;AccessHandle &quot; &lt;&lt; ip &lt;&lt; std::endl;
      //   return false;
      // }
      return true;
    }
    int CreateWorkerSpecificData(void** data) const override {
      return 0;
    }
    int DeleteWorkerSpecificData(void* data) const override {
      return 0;
    }
    void DestConnectFailedHandle(std::string ip_port, std::string reason) const override {
    }
  };

  ReplClientConnFactory conn_factory_;
  ReplClientHandle handle_;
};
</code></pre></div><p>由于每次client_thread都会将新连接通过PikaReplClientConn来初始化，故每次有事件驱动的时候就调用该PikaReplClientConn的Dealmessage函数，来处理解析的数据。</p> <div class="language-c++ extra-class"><pre class="language-text"><code>int PikaReplClientConn::DealMessage() {
  std::shared_ptr&lt;InnerMessage::InnerResponse&gt; response =  std::make_shared&lt;InnerMessage::InnerResponse&gt;();
  ::google::protobuf::io::ArrayInputStream input(rbuf_ + cur_pos_ - header_len_, header_len_);
  ::google::protobuf::io::CodedInputStream decoder(&amp;input);
  decoder.SetTotalBytesLimit(g_pika_conf-&gt;max_conn_rbuf_size(), g_pika_conf-&gt;max_conn_rbuf_size());
  bool success = response-&gt;ParseFromCodedStream(&amp;decoder) &amp;&amp; decoder.ConsumedEntireMessage();  
  if (!success) {
    LOG(WARNING) &lt;&lt; &quot;ParseFromArray FAILED! &quot; &lt;&lt; &quot; msg_len: &quot; &lt;&lt; header_len_;
    g_pika_server-&gt;SyncError();
    return -1;
  }
  switch (response-&gt;type()) {  // 根据协议解析的类型来判断执行什么操作
    case InnerMessage::kMetaSync:
    {
      ReplClientTaskArg* task_arg = new ReplClientTaskArg(response, std::dynamic_pointer_cast&lt;PikaReplClientConn&gt;(shared_from_this()));
      g_pika_rm-&gt;ScheduleReplClientBGTask(&amp;PikaReplClientConn::HandleMetaSyncResponse, static_cast&lt;void*&gt;(task_arg));  // 如果是元数据同步，将该事件放入到处理线程池中执行
      break;
    }
    case InnerMessage::kDBSync:
    {
      ReplClientTaskArg* task_arg = new ReplClientTaskArg(response, std::dynamic_pointer_cast&lt;PikaReplClientConn&gt;(shared_from_this()));
      g_pika_rm-&gt;ScheduleReplClientBGTask(&amp;PikaReplClientConn::HandleDBSyncResponse, static_cast&lt;void*&gt;(task_arg));
      break;
    }
    case InnerMessage::kTrySync:
    {
      ReplClientTaskArg* task_arg = new ReplClientTaskArg(response, std::dynamic_pointer_cast&lt;PikaReplClientConn&gt;(shared_from_this()));
      g_pika_rm-&gt;ScheduleReplClientBGTask(&amp;PikaReplClientConn::HandleTrySyncResponse, static_cast&lt;void*&gt;(task_arg));  // 如果是同步则放入线程池中去执行HandleTrySyncResponse函数
      break;
    }
    case InnerMessage::kBinlogSync:
    {
      DispatchBinlogRes(response);  // binlog同步处理
      break;
    }
    case InnerMessage::kRemoveSlaveNode:
    {
      ReplClientTaskArg* task_arg = new ReplClientTaskArg(response, std::dynamic_pointer_cast&lt;PikaReplClientConn&gt;(shared_from_this()));
      g_pika_rm-&gt;ScheduleReplClientBGTask(&amp;PikaReplClientConn::HandleRemoveSlaveNodeResponse, static_cast&lt;void*&gt;(task_arg));
      break;
    }
    default:
      break;
  }
  return 0;
}
</code></pre></div><p>至此，一个pika_repl_client的整个的处理流程就清晰，即每次都会根据协议调用PikaReplClientConn的DealMessage函数，将每个执行任务放入线程池中去处理。</p> <h4 id="pika-repl-server线程"><a href="#pika-repl-server线程" class="header-anchor">#</a> pika_repl_server线程</h4> <p>该线程的核心思想与pika_repl_client的处理流程差不多，只不过在pink中对应的是HolyThread，处理流程大同小异，最终调用的就是PikaReplServerConn的DealMessage方法。</p> <div class="language-c++ extra-class"><pre class="language-text"><code>int PikaReplServerConn::DealMessage() {
  std::shared_ptr&lt;InnerMessage::InnerRequest&gt; req = std::make_shared&lt;InnerMessage::InnerRequest&gt;();
  bool parse_res = req-&gt;ParseFromArray(rbuf_ + cur_pos_ - header_len_, header_len_);
  if (!parse_res) {
    LOG(WARNING) &lt;&lt; &quot;Pika repl server connection pb parse error.&quot;;
    return -1;
  }
  switch (req-&gt;type()) {
    case InnerMessage::kMetaSync:
    {
      ReplServerTaskArg* task_arg = new ReplServerTaskArg(req, std::dynamic_pointer_cast&lt;PikaReplServerConn&gt;(shared_from_this()));
      g_pika_rm-&gt;ScheduleReplServerBGTask(&amp;PikaReplServerConn::HandleMetaSyncRequest, task_arg);
      break;
    }
    case InnerMessage::kTrySync:
    {
      ReplServerTaskArg* task_arg = new ReplServerTaskArg(req, std::dynamic_pointer_cast&lt;PikaReplServerConn&gt;(shared_from_this()));
      g_pika_rm-&gt;ScheduleReplServerBGTask(&amp;PikaReplServerConn::HandleTrySyncRequest, task_arg);
      break;
    }
    case InnerMessage::kDBSync:
    {
      ReplServerTaskArg* task_arg = new ReplServerTaskArg(req, std::dynamic_pointer_cast&lt;PikaReplServerConn&gt;(shared_from_this()));
      g_pika_rm-&gt;ScheduleReplServerBGTask(&amp;PikaReplServerConn::HandleDBSyncRequest, task_arg);
      break;
    }
    case InnerMessage::kBinlogSync:
    {
      ReplServerTaskArg* task_arg = new ReplServerTaskArg(req, std::dynamic_pointer_cast&lt;PikaReplServerConn&gt;(shared_from_this()));
      g_pika_rm-&gt;ScheduleReplServerBGTask(&amp;PikaReplServerConn::HandleBinlogSyncRequest, task_arg);
      break;
    }
    case InnerMessage::kRemoveSlaveNode:
    {
      ReplServerTaskArg* task_arg = new ReplServerTaskArg(req, std::dynamic_pointer_cast&lt;PikaReplServerConn&gt;(shared_from_this()));
      g_pika_rm-&gt;ScheduleReplServerBGTask(&amp;PikaReplServerConn::HandleRemoveSlaveNodeRequest, task_arg);
      break;
    }
    default:
      break;
  }
  return 0;
}

</code></pre></div><h3 id="主从同步的流程"><a href="#主从同步的流程" class="header-anchor">#</a> 主从同步的流程</h3> <p>pika_repl_server的流程可用如图描述。</p> <p><img src="https://img-blog.csdnimg.cn/f5f65e0cb6e74b45a9afbc45933ab12f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5bCP5bGL5a2Q5aSn5L6g,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p> <p>pika_repl_client的流程可用如图描述。</p> <p><img src="https://img-blog.csdnimg.cn/8cd2006d23814034b0b6372412506363.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5bCP5bGL5a2Q5aSn5L6g,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p> <p>主从的状态机流程如下。</p> <p><img src="https://img-blog.csdnimg.cn/9fbd751015384d198c2ea514e4ca84b6.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5bCP5bGL5a2Q5aSn5L6g,size_12,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p> <p>通过如上三个图就可以能够明白pika官网描述的主从同步的流程图。</p> <p><a href="https://github.com/OpenAtomFoundation/pika/wiki/pika-%E5%A2%9E%E9%87%8F%E5%90%8C%E6%AD%A5" target="_blank" rel="noopener noreferrer">pika-增量同步<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p><a href="https://github.com/OpenAtomFoundation/pika/wiki/pika-%E5%85%A8%E5%90%8C%E6%AD%A5" target="_blank" rel="noopener noreferrer">pika-全同步<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <h2 id="总结"><a href="#总结" class="header-anchor">#</a> 总结</h2> <p>本文根据pika官网的流程，分析了一下pika主从的一个大致流程，其中还包含了很多的技术细节限于本文篇幅并没有详尽分析，主要通过原理流程的一个分析来查看了主从同步的状态机线程，和主从同步的线程模型的基本原理。由于本人才疏学浅，如有错误请批评指正。</p></div></section> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev"><a href="/document/design/增量同步.html" class="prev">
          增量同步
        </a></span> <span class="next"><a href="/document/design/副本一致性.html">
          副本一致性
        </a></span></p></div> <div class="comments-wrapper"><!----></div></main></div> <!----></div> <ul class="sub-sidebar sub-sidebar-wrapper" style="width:12rem;" data-v-b57cc07c data-v-7dd95ae2><li class="level-2" data-v-b57cc07c><a href="/document/design/pika%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E5%8E%9F%E7%90%86.html#pika主从同步" class="sidebar-link reco-side-pika主从同步" data-v-b57cc07c>pika主从同步</a></li><li class="level-2" data-v-b57cc07c><a href="/document/design/pika%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E5%8E%9F%E7%90%86.html#pika主从同步原理" class="sidebar-link reco-side-pika主从同步原理" data-v-b57cc07c>pika主从同步原理</a></li><li class="level-3" data-v-b57cc07c><a href="/document/design/pika%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E5%8E%9F%E7%90%86.html#auxiliary-thread线程" class="sidebar-link reco-side-auxiliary-thread线程" data-v-b57cc07c>auxiliary_thread线程</a></li><li class="level-3" data-v-b57cc07c><a href="/document/design/pika%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E5%8E%9F%E7%90%86.html#pika-repl-client和pika-repl-server-线程" class="sidebar-link reco-side-pika-repl-client和pika-repl-server-线程" data-v-b57cc07c>pika_repl_client和pika_repl_server_线程</a></li><li class="level-3" data-v-b57cc07c><a href="/document/design/pika%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E5%8E%9F%E7%90%86.html#主从同步的流程" class="sidebar-link reco-side-主从同步的流程" data-v-b57cc07c>主从同步的流程</a></li><li class="level-2" data-v-b57cc07c><a href="/document/design/pika%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E5%8E%9F%E7%90%86.html#总结" class="sidebar-link reco-side-总结" data-v-b57cc07c>总结</a></li></ul></div></div></div><div class="global-ui"><div class="back-to-ceiling" style="right:1rem;bottom:6rem;width:2.5rem;height:2.5rem;border-radius:.25rem;line-height:2.5rem;display:none;" data-v-c6073ba8 data-v-c6073ba8><svg t="1574745035067" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="5404" class="icon" data-v-c6073ba8><path d="M526.60727968 10.90185116a27.675 27.675 0 0 0-29.21455937 0c-131.36607665 82.28402758-218.69155461 228.01873535-218.69155402 394.07834331a462.20625001 462.20625001 0 0 0 5.36959153 69.94390903c1.00431239 6.55289093-0.34802892 13.13561351-3.76865779 18.80351572-32.63518765 54.11355614-51.75690182 118.55860487-51.7569018 187.94566865a371.06718723 371.06718723 0 0 0 11.50484808 91.98906777c6.53300375 25.50556257 41.68394495 28.14064038 52.69160883 4.22606766 17.37162448-37.73630017 42.14135425-72.50938081 72.80769204-103.21549295 2.18761121 3.04276886 4.15646224 6.24463696 6.40373557 9.22774369a1871.4375 1871.4375 0 0 0 140.04691725 5.34970492 1866.36093723 1866.36093723 0 0 0 140.04691723-5.34970492c2.24727335-2.98310674 4.21612437-6.18497483 6.3937923-9.2178004 30.66633723 30.70611158 55.4360664 65.4791928 72.80769147 103.21549355 11.00766384 23.91457269 46.15860503 21.27949489 52.69160879-4.22606768a371.15156223 371.15156223 0 0 0 11.514792-91.99901164c0-69.36717486-19.13165746-133.82216804-51.75690182-187.92578088-3.42062944-5.66790279-4.76302748-12.26056868-3.76865837-18.80351632a462.20625001 462.20625001 0 0 0 5.36959269-69.943909c-0.00994388-166.08943902-87.32547796-311.81420293-218.6915546-394.09823051zM605.93803103 357.87693858a93.93749974 93.93749974 0 1 1-187.89594924 6.1e-7 93.93749974 93.93749974 0 0 1 187.89594924-6.1e-7z" p-id="5405" data-v-c6073ba8></path><path d="M429.50777625 765.63860547C429.50777625 803.39355007 466.44236686 1000.39046097 512.00932183 1000.39046097c45.56695499 0 82.4922232-197.00623328 82.5015456-234.7518555 0-37.75494459-36.9345906-68.35043303-82.4922232-68.34111062-45.57627738-0.00932239-82.52019037 30.59548842-82.51086798 68.34111062z" p-id="5406" data-v-c6073ba8></path></svg></div></div></div>
    <script src="/assets/js/app.fdecc826.js" defer></script><script src="/assets/js/7.1224f65b.js" defer></script><script src="/assets/js/2.9fbd6685.js" defer></script><script src="/assets/js/1.77f24ecd.js" defer></script><script src="/assets/js/51.b06f7ce0.js" defer></script>
  </body>
</html>
